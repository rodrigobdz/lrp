{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation\n",
    "\n",
    "This notebook a follow-up to [numerical-instability.ipynb](./numerical-instability.ipynb) and [num-instability-standard-deviation](./num-instability-standard-deviation.ipynb).\n",
    "\n",
    "Requirements:\n",
    "- **Disable heuristic to reproduce numerical instability and calculate the standard deviation in this case.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging\n",
    "\n",
    "Detect `NaN` in Tensor computations (e.g., as a result of 0/0).\n",
    "\n",
    "Enable anomaly detection for autograd engine.\n",
    "Any backward computation that generate “nan” value will raise an error.\n",
    "\n",
    "- Discussion: https://discuss.pytorch.org/t/finding-source-of-nan-in-forward-pass/51153/3\n",
    "- Docs: https://pytorch.org/docs/stable/autograd.html#torch.autograd.set_detect_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x10fc34c10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRP setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Callable, Dict, List, Tuple, Union\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import lrp.plot\n",
    "import lrp.rules as rules\n",
    "from lrp import image, norm\n",
    "from lrp.core import LRP\n",
    "from lrp.filter import LayerFilter\n",
    "from lrp.rules import LrpEpsilonRule, LrpGammaRule, LrpZBoxRule, LrpZeroRule\n",
    "from lrp.zennit.types import AvgPool, Linear\n",
    "\n",
    "# Normalization\n",
    "norm_fn: Callable[[torch.Tensor], torch.Tensor] = norm.ImageNetNorm()\n",
    "\n",
    "import numpy\n",
    "# Input data\n",
    "from torchvision import transforms\n",
    "\n",
    "from lrp import image\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrp_workflow(img_path: str):\n",
    "  img: numpy.array = image.load_normalized_img(img_path)\n",
    "\n",
    "  transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize(mean, std)\n",
    "  ])\n",
    "\n",
    "  inv_norm = transforms.Normalize(\n",
    "    mean= [-m/s for m, s in zip(mean, std)],\n",
    "    std= [1/s for s in std]\n",
    "  )\n",
    "\n",
    "  X = transform(img)\n",
    "  # Simulate batch by adding a new dimension\n",
    "  X = torch.unsqueeze(X, 0)\n",
    "\n",
    "  # Model\n",
    "  model = torchvision.models.vgg16(pretrained=True)\n",
    "  model.eval()\n",
    "\n",
    "  # Low and high parameters for zB-rule\n",
    "  batch_size: int = 1\n",
    "  shape: Tuple[int] = (batch_size, 3, 224, 224)\n",
    "\n",
    "  low: torch.Tensor = norm_fn(torch.zeros(*shape))\n",
    "  high: torch.Tensor = norm_fn(torch.ones(*shape))\n",
    "\n",
    "  # Init layer filter\n",
    "  vgg16_target_types: Tuple[type] = (Linear, AvgPool)\n",
    "  filter_by_layer_index_type = LayerFilter(model)\n",
    "  filter_by_layer_index_type.set_target_types(vgg16_target_types)\n",
    "\n",
    "  name_map: List[Tuple[List[str], rules.LrpRule, Dict[str, Union[torch.Tensor, float]]]]\n",
    "\n",
    "  name_map = [\n",
    "      (filter_by_layer_index_type(lambda n: n == 0), LrpZBoxRule, {'low': low, 'high': high}),\n",
    "      (filter_by_layer_index_type(lambda n: 1 <= n <= 16), LrpGammaRule, {'gamma': 0}),\n",
    "      (filter_by_layer_index_type(lambda n: 17 <= n <= 30), LrpEpsilonRule, {'epsilon': 0.25}),\n",
    "      (filter_by_layer_index_type(lambda n: 31 <= n), LrpZeroRule, {}),\n",
    "  ]\n",
    "\n",
    "  lrp_example = LRP(model)\n",
    "  lrp_example.convert_layers(name_map)\n",
    "\n",
    "  R: torch.Tensor = lrp_example.relevance(X)\n",
    "\n",
    "  # fig, ax = plt.subplots()\n",
    "  # img: numpy.array = image.load_normalized_img(img_path)\n",
    "  # lrp.plot.heatmap(R[0].sum(dim=0).detach().numpy(), width=2, height=2, show_plot=False, fig=ax)\n",
    "\n",
    "  # transform = transforms.Compose([\n",
    "  #     transforms.ToTensor(),\n",
    "  #     transforms.Resize((224, 224)),\n",
    "  #     transforms.ConvertImageDtype(torch.float),\n",
    "  # ])\n",
    "\n",
    "  # ax.imshow(transform(img).numpy().transpose(1,2,0), alpha=0.2)\n",
    "\n",
    "  return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate standard deviation of all castle images in ILSVRC 2012's validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "castle std: 0.44248613715171814 std_pooled: 1.2392504215240479\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Image is in RGB mode with range [0,1]\n",
    "img_path = f'../data/castle.jpg'\n",
    "# Extract image name without extension\n",
    "img_name = os.path.basename(img_path).split('.')[0]\n",
    "\n",
    "R = lrp_workflow(img_path)\n",
    "torch.save(R, f'./artifacts/num-instability-standard-deviation/relevance_scores_{img_name}.pt')\n",
    "pooled_relevance_scores = R[0].sum(dim=0)\n",
    "torch.save(pooled_relevance_scores, f'./artifacts/num-instability-standard-deviation/pooled_relevance_scores_{img_name}.csv')\n",
    "\n",
    "with open(f'./artifacts/num-instability-standard-deviation/std_relevance_scores_{img_name}.txt', \"w\") as f:\n",
    "  f.write(f'Standard deviation of relevance scores of {img_name}: {torch.std(R)}')\n",
    "\n",
    "with open(f'./artifacts/num-instability-standard-deviation/std_pooled_relevance_scores_{img_name}.txt', \"w\") as f:\n",
    "  f.write(f'Standard deviation of pooled relevance scores of {img_name}: {torch.std(R[0].sum(dim=0))}')\n",
    "\n",
    "print(f'{img_name} std: {torch.std(R)} std_pooled: {torch.std(R[0].sum(dim=0))}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75ce43d651e7ed94697eb2e711875277eac8301956987ff4981f0cf80965cb87"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
