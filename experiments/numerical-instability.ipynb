{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate numerical instability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recall the hint at the heuristic in the algorithm presented in the paper \"_LRP: An Overview_\":\n",
    "\n",
    "> The small additive term 1e-9 in the division simply enforces the behavior 0/0 = 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "1. The function `stabilize` in [lrp/zennit/core.py](../lrp/zennit/core.py) needs to be set to the values provided in the next section.\n",
    "1. The image to load should be [castle.jpg](../data/castle.jpg).\n",
    "1. The minimal working example should have the following rule-layer mapping:\n",
    "\n",
    "```python\n",
    "name_map = [\n",
    "    (filter_by_layer_index_type(lambda n: n == 0), LrpZBoxRule, {'low': low, 'high': high}),\n",
    "    (filter_by_layer_index_type(lambda n: 1 <= n <= 16), LrpGammaRule, {'gamma': 0}),\n",
    "    (filter_by_layer_index_type(lambda n: 17 <= n <= 30), LrpEpsilonRule, {'epsilon': 0.25}),\n",
    "    (filter_by_layer_index_type(lambda n: 31 <= n), LrpZeroRule, {}),\n",
    "]\n",
    "```\n",
    "\n",
    "## Root cause of numerical instability\n",
    "\n",
    "The issue arises depending on the implementation of the [`stabilize`](https://github.com/rodrigobdz/lrp/blob/c163c519599d0dd1320e8ed8cab5daac1978fe20/lrp/zennit/core.py#L16-L25) method and it is input-dependent— it doesn't appear if we use [castle2.jpg](../data/castle2.jpg) instead.\n",
    "\n",
    "The following implementations have been tested:\n",
    "\n",
    "```python\n",
    "epsilon: float = 0.1\n",
    "dividend: torch.Tensor = torch.Tensor([-epsilon, 5, -5, -10])\n",
    "# tensor([ -0.1000,   5.0000,  -5.0000, -10.0000])\n",
    "```\n",
    "\n",
    "1. **Heuristic:** Add epsilon to the absolute value of the dividend (zennit's) conserving the sign: \n",
    "\n",
    "    ```python\n",
    "    dividend + ((dividend == 0.).to(dividend) + dividend.sign()) * epsilon\n",
    "    ```\n",
    "\n",
    "    Example:\n",
    "\n",
    "    ```python\n",
    "    dividend + ((dividend == 0.).to(dividend) + dividend.sign()) * epsilon\n",
    "    # tensor([ -0.2000,   5.1000,  -5.1000, -10.1000])\n",
    "    ```\n",
    "\n",
    "2. **Heuristic:** Scale epsilon according to dividend's magnitude using quadratic mean\n",
    "    \n",
    "    ```python\n",
    "    dividend + epsilon * (dividend**2).mean()**.5 + 1e-9\n",
    "    ```\n",
    "\n",
    "    Example:\n",
    "\n",
    "    ```python\n",
    "    dividend + epsilon * (dividend**2).mean()**.5 + 1e-9\n",
    "    # tensor([ 0.5124,  5.6124, -4.3876, -9.3876])\n",
    "    ```\n",
    "\n",
    "3. **Vanilla:** Add epsilon to dividend without heuristics\n",
    "\n",
    "    ```python\n",
    "    dividend + epsilon\n",
    "    ```\n",
    "\n",
    "    Example:\n",
    "\n",
    "    ```python\n",
    "    dividend + epsilon\n",
    "    # tensor([ 0.0000,  5.1000, -4.9000, -9.9000])\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging\n",
    "\n",
    "Detect `NaN` in Tensor computations (e.g., as a result of 0/0).\n",
    "\n",
    "Enable anomaly detection for autograd engine.\n",
    "Any backward computation that generate “nan” value will raise an error.\n",
    "\n",
    "- Discussion: https://discuss.pytorch.org/t/finding-source-of-nan-in-forward-pass/51153/3\n",
    "- Docs: https://pytorch.org/docs/stable/autograd.html#torch.autograd.set_detect_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x108a0a250>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducing LRP's \"bug\"\n",
    "\n",
    "LRP setup (scaffold?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Callable\n",
    "import torchvision\n",
    "import numpy\n",
    "import torch\n",
    "from lrp import norm, image\n",
    "\n",
    "from lrp.rules import LrpZBoxRule, LrpGammaRule, LrpEpsilonRule, LrpZeroRule\n",
    "\n",
    "from typing import List, Dict, Union, Tuple\n",
    "from lrp.filter import LayerFilter\n",
    "from lrp.zennit.types import AvgPool, Linear\n",
    "import lrp.rules as rules\n",
    "\n",
    "from lrp.core import LRP\n",
    "\n",
    "import lrp.plot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Normalization\n",
    "norm_fn: Callable[[torch.Tensor], torch.Tensor] = norm.ImageNetNorm()\n",
    "\n",
    "# Input data\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy\n",
    "from lrp import image\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Resize((224, 224)),\n",
    "  transforms.ConvertImageDtype(torch.float),\n",
    "  transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "inv_norm = transforms.Normalize(\n",
    "  mean= [-m/s for m, s in zip(mean, std)],\n",
    "  std= [1/s for s in std]\n",
    ")\n",
    "\n",
    "# Image is in RGB mode with range [0,1]\n",
    "img_path = '../data/castle.jpg'\n",
    "img: numpy.array = image.load_normalized_img(img_path)\n",
    "X = transform(img)\n",
    "# Simulate batch by adding a new dimension\n",
    "X = torch.unsqueeze(X, 0)\n",
    "\n",
    "# Model\n",
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Low and high parameters for zB-rule\n",
    "batch_size: int = 1\n",
    "shape: Tuple[int] = (batch_size, 3, 224, 224)\n",
    "\n",
    "low: torch.Tensor = norm_fn(torch.zeros(*shape))\n",
    "high: torch.Tensor = norm_fn(torch.ones(*shape))\n",
    "\n",
    "# Init layer filter\n",
    "vgg16_target_types: Tuple[type] = (Linear, AvgPool)\n",
    "filter_by_layer_index_type = LayerFilter(model)\n",
    "filter_by_layer_index_type.set_target_types(vgg16_target_types)\n",
    "\n",
    "name_map: List[Tuple[List[str], rules.LrpRule, Dict[str, Union[torch.Tensor, float]]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LRP rule-layer mapping and computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Error detected in MulBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/sy/f1d_3n0s0tzct5c9xxk30mlc0000gn/T/ipykernel_58729/401066064.py\", line 11, in <module>\n",
      "    R: torch.Tensor = lrp_example.relevance(X)\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/lrp/core.py\", line 117, in relevance\n",
      "    self.model.forward(X)[0].max().backward()\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/torchvision/models/vgg.py\", line 52, in forward\n",
      "    x = self.classifier(x)\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 141, in forward\n",
      "    input = module(input)\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/lrp/rules.py\", line 88, in forward\n",
      "    return super().forward_mod_gradient(z, output)\n",
      "  File \"/Users/rodrigobermudezschettino/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/lrp/rules.py\", line 55, in forward_mod_gradient\n",
      "    return z * (output / z).detach()\n",
      " (Triggered internally at  ../torch/csrc/autograd/python_anomaly_mode.cpp:104.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'MulBackward0' returned nan values in its 0th output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sy/f1d_3n0s0tzct5c9xxk30mlc0000gn/T/ipykernel_58729/401066064.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlrp_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mR\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlrp_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelevance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/lrp/core.py\u001b[0m in \u001b[0;36mrelevance\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# Stores value of gradient in X.grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# [0].max() retrieves the maximum activation/relevance in the first layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLrpZBoxRule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/personal/unterlagen/bildung/uni/master/masterarbeit/code/lrp/venv/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function 'MulBackward0' returned nan values in its 0th output."
     ]
    }
   ],
   "source": [
    "name_map = [\n",
    "    (filter_by_layer_index_type(lambda n: n == 0), LrpZBoxRule, {'low': low, 'high': high}),\n",
    "    (filter_by_layer_index_type(lambda n: 1 <= n <= 16), LrpGammaRule, {'gamma': 0}),\n",
    "    (filter_by_layer_index_type(lambda n: 17 <= n <= 30), LrpEpsilonRule, {'epsilon': 0.25}),\n",
    "    (filter_by_layer_index_type(lambda n: 31 <= n), LrpZeroRule, {}),\n",
    "]\n",
    "\n",
    "lrp_example = LRP(model)\n",
    "lrp_example.convert_layers(name_map)\n",
    "\n",
    "R: torch.Tensor = lrp_example.relevance(X)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "img: numpy.array = image.load_normalized_img(img_path)\n",
    "lrp.plot.heatmap(R[0].sum(dim=0).detach().numpy(), width=2, height=2, show_plot=False, fig=ax)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "])\n",
    "\n",
    "ax.imshow(transform(img).numpy().transpose(1,2,0), alpha=0.2)\n",
    "# fig.savefig('/Users/rodrigobermudezschettino/Downloads/castle_lrp.png', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect results\n",
    "\n",
    "Try to find the correlation between the patches in the heatmaps and the computed relevance scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display min. and max. values in relevance scores\n",
    "\n",
    "Relevance scores indicating pixel-wise contributions:\n",
    "```python\n",
    "R[0].sum(dim=0)\n",
    "```\n",
    "\n",
    "> The relevance scores obtained in the pixel layer can now be summed over the RGB channels to indicate actual pixel-wise contributions.\n",
    "> \n",
    "> Source: lrp-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividend + epsilon\n",
    "a = R[0].sum(dim=0).detach()\n",
    "print('Total', torch.numel(a))\n",
    "print('negative', torch.numel(a[a < 0.]))\n",
    "print('zero', torch.numel(a[a == 0.]))\n",
    "print('positive', torch.numel(a[a > 0.]))\n",
    "\n",
    "display(torch.aminmax(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map indices of relevance scores to pixel values in input image and its gradient\n",
    "\n",
    "The input image is stored in `X` and the relevance scores are stored in `R`. We also look into the gradient of the input image `X.grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R {R.shape}')\n",
    "print(f'X {X.shape}')\n",
    "print(f'X.grad {X.grad.shape}')\n",
    "print('\\n')\n",
    "\n",
    "a = (R[0].detach()==torch.max(R[0].detach())).nonzero()\n",
    "i, h, k = a[0, :].tolist()\n",
    "\n",
    "print(f'R max indices: {i} {h} {k}')\n",
    "\n",
    "print(f'X [0][{i} {h} {k}] {X[0][i, h, k].item()}')\n",
    "print(f'X.grad [0][{i} {h} {k}] {X.grad[0][i, h, k].item()}')\n",
    "print(f'R [0][{i} {h} {k}] {R[0].detach()[i, h, k].item()}')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "a = (R[0].detach()==torch.min(R[0].detach())).nonzero()\n",
    "i, h, k = a[0, :].tolist()\n",
    "\n",
    "print(f'R min indices: {i} {h} {k}')\n",
    "\n",
    "print(f'X [0][{i} {h} {k}] {X[0][i, h, k].item()}')\n",
    "print(f'X.grad [0][{i} {h} {k}] {X.grad[0][i, h, k].item()}')\n",
    "print(f'R [0][{i} {h} {k}] {R[0].detach()[i, h, k].item()}')\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# print('X max')\n",
    "a = (X.grad==torch.max(X.grad)).nonzero()\n",
    "z, i, h, k = a[0, :].tolist()\n",
    "\n",
    "print(f'X.grad max indices: {z} {i} {h} {k}')\n",
    "print(f'X [{z} {i} {h} {k}]: {X[z, i, h, k].item()}')\n",
    "print(f'X.grad [{z} {i} {h} {k}]: {X.grad[z, i, h, k].item()}')\n",
    "\n",
    "# print('\\nX min')\n",
    "print('\\n')\n",
    "\n",
    "a = (X.grad==torch.min(X.grad)).nonzero()\n",
    "z, i, h, k = a[0, :].tolist()\n",
    "\n",
    "print(f'X.grad min indices: {z} {i} {h} {k}')\n",
    "print(f'X [{z} {i} {h} {k}]: {X[z, i, h, k].item()}')\n",
    "print(f'X.grad [{z} {i} {h} {k}]: {X.grad[z, i, h, k].item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect X.grad minima and maxima\n",
    "\n",
    "Compute `X.grad`'s minima and maxima and show the values of `X` at these minima and maxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.min(X.grad))\n",
    "min_x_grad = (X.grad==torch.min(X.grad)).nonzero()\n",
    "z, i, h, k = min_x_grad[0, :].tolist()\n",
    "\n",
    "a = X[z, i, h, k].item()\n",
    "b = X.grad[z, i, h, k].item()\n",
    "print(f'X min {a} X.grad min {b}')\n",
    "print(a*b)\n",
    "\n",
    "r = R[0].detach()\n",
    "print(r.shape)\n",
    "display(torch.aminmax(r))\n",
    "\n",
    "r = R[0].sum(dim=0).detach()\n",
    "print(r.shape)\n",
    "display(torch.aminmax(r))\n",
    "\n",
    "print(f'X.grad min indices: {z} {i} {h} {k}')\n",
    "print(f'X [{z} {i} {h} {k}]: {X[z, i, h, k].item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for NaN values in relevance scores\n",
    "\n",
    "- The numerical instability is reproducible with `lrp-tutorial`, where values turn to `NaN`.\n",
    "  Results saved to file and committed to git ([robust](https://git.tu-berlin.de/rodrigobdz/lrp-tutorial/-/blob/955e0d495ab022ca51174feb978e82073e6672af/tutorial.ipynb), [error reproduction](https://git.tu-berlin.de/rodrigobdz/lrp-tutorial/-/blob/36d6de8db6f440aa8eebed291e93bdfc2c83f74f/tutorial.ipynb)).\n",
    "- This repo's LRP leverages the forward-hook architecture implementation. Inspect patches in heatmaps (blown-up values in magnitude) to **see if relevance scores contain `NaN` values to verify if the behavior is consistent.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(R.isnan().any())\n",
    "display(X.isnan().any())\n",
    "display(X.grad.isnan().any())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75ce43d651e7ed94697eb2e711875277eac8301956987ff4981f0cf80965cb87"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
