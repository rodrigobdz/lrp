{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation\n",
    "\n",
    "Apply heuristic to many images to see if scores are outside of standard deviation and ensure the heuristic works for any given image. This notebook a follow-up to [numerical-instability.ipynb](./numerical-instability.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging\n",
    "\n",
    "Detect `NaN` in Tensor computations (e.g., as a result of 0/0).\n",
    "\n",
    "Enable anomaly detection for autograd engine.\n",
    "Any backward computation that generate “nan” value will raise an error.\n",
    "\n",
    "- Discussion: https://discuss.pytorch.org/t/finding-source-of-nan-in-forward-pass/51153/3\n",
    "- Docs: https://pytorch.org/docs/stable/autograd.html#torch.autograd.set_detect_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x10b962730>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRP setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Callable\n",
    "import torchvision\n",
    "import numpy\n",
    "import torch\n",
    "from lrp import norm, image\n",
    "\n",
    "from lrp.rules import LrpZBoxRule, LrpGammaRule, LrpEpsilonRule, LrpZeroRule\n",
    "\n",
    "from typing import List, Dict, Union, Tuple\n",
    "from lrp.filter import LayerFilter\n",
    "from lrp.zennit.types import AvgPool, Linear\n",
    "import lrp.rules as rules\n",
    "\n",
    "from lrp.core import LRP\n",
    "\n",
    "import lrp.plot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Normalization\n",
    "norm_fn: Callable[[torch.Tensor], torch.Tensor] = norm.ImageNetNorm()\n",
    "\n",
    "# Input data\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy\n",
    "from lrp import image\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrp_workflow(img_path: str):\n",
    "  img: numpy.array = image.load_normalized_img(img_path)\n",
    "\n",
    "  transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize(mean, std)\n",
    "  ])\n",
    "\n",
    "  inv_norm = transforms.Normalize(\n",
    "    mean= [-m/s for m, s in zip(mean, std)],\n",
    "    std= [1/s for s in std]\n",
    "  )\n",
    "\n",
    "  X = transform(img)\n",
    "  # Simulate batch by adding a new dimension\n",
    "  X = torch.unsqueeze(X, 0)\n",
    "\n",
    "  # Model\n",
    "  model = torchvision.models.vgg16(pretrained=True)\n",
    "  model.eval()\n",
    "\n",
    "  # Low and high parameters for zB-rule\n",
    "  batch_size: int = 1\n",
    "  shape: Tuple[int] = (batch_size, 3, 224, 224)\n",
    "\n",
    "  low: torch.Tensor = norm_fn(torch.zeros(*shape))\n",
    "  high: torch.Tensor = norm_fn(torch.ones(*shape))\n",
    "\n",
    "  # Init layer filter\n",
    "  vgg16_target_types: Tuple[type] = (Linear, AvgPool)\n",
    "  filter_by_layer_index_type = LayerFilter(model)\n",
    "  filter_by_layer_index_type.set_target_types(vgg16_target_types)\n",
    "\n",
    "  name_map: List[Tuple[List[str], rules.LrpRule, Dict[str, Union[torch.Tensor, float]]]]\n",
    "\n",
    "  name_map = [\n",
    "      (filter_by_layer_index_type(lambda n: n == 0), LrpZBoxRule, {'low': low, 'high': high}),\n",
    "      (filter_by_layer_index_type(lambda n: 1 <= n <= 16), LrpGammaRule, {'gamma': 0}),\n",
    "      (filter_by_layer_index_type(lambda n: 17 <= n <= 30), LrpEpsilonRule, {'epsilon': 0.25}),\n",
    "      (filter_by_layer_index_type(lambda n: 31 <= n), LrpZeroRule, {}),\n",
    "  ]\n",
    "\n",
    "  lrp_example = LRP(model)\n",
    "  lrp_example.convert_layers(name_map)\n",
    "\n",
    "  R: torch.Tensor = lrp_example.relevance(X)\n",
    "\n",
    "  # fig, ax = plt.subplots()\n",
    "  # img: numpy.array = image.load_normalized_img(img_path)\n",
    "  # lrp.plot.heatmap(R[0].sum(dim=0).detach().numpy(), width=2, height=2, show_plot=False, fig=ax)\n",
    "\n",
    "  # transform = transforms.Compose([\n",
    "  #     transforms.ToTensor(),\n",
    "  #     transforms.Resize((224, 224)),\n",
    "  #     transforms.ConvertImageDtype(torch.float),\n",
    "  # ])\n",
    "\n",
    "  # ax.imshow(transform(img).numpy().transpose(1,2,0), alpha=0.2)\n",
    "\n",
    "  return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate standard deviation of all castle images in ILSVRC 2012's validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -> ILSVRC2012_val_00041354 std: 0.000979261938482523 std_pooled: 0.0027281129732728004\n",
      "2 -> ILSVRC2012_val_00003916 std: 0.001780993421562016 std_pooled: 0.004910173825919628\n",
      "3 -> ILSVRC2012_val_00002487 std: 0.0011073173955082893 std_pooled: 0.0030731644947081804\n",
      "4 -> ILSVRC2012_val_00019377 std: 0.0014270085375756025 std_pooled: 0.003981767687946558\n",
      "5 -> ILSVRC2012_val_00039597 std: 0.001965473871678114 std_pooled: 0.0053999838419258595\n",
      "6 -> ILSVRC2012_val_00005338 std: 0.0010363674955442548 std_pooled: 0.002890840405598283\n",
      "7 -> ILSVRC2012_val_00029345 std: 0.001532531576231122 std_pooled: 0.004246695898473263\n",
      "8 -> ILSVRC2012_val_00044012 std: 0.001191089628264308 std_pooled: 0.0033124773763120174\n",
      "9 -> ILSVRC2012_val_00041139 std: 0.0013129771687090397 std_pooled: 0.0036860639229416847\n",
      "10 -> ILSVRC2012_val_00004071 std: 0.0010650560725480318 std_pooled: 0.0029643001034855843\n",
      "11 -> ILSVRC2012_val_00037341 std: 0.0016428256640210748 std_pooled: 0.004605838563293219\n",
      "12 -> ILSVRC2012_val_00014661 std: 0.0010295686079189181 std_pooled: 0.0028561463113874197\n",
      "13 -> ILSVRC2012_val_00006522 std: 0.0011949753388762474 std_pooled: 0.0033470953349024057\n",
      "14 -> ILSVRC2012_val_00019157 std: 0.0009208245319314301 std_pooled: 0.002570845652371645\n",
      "15 -> ILSVRC2012_val_00027848 std: 0.0009899092838168144 std_pooled: 0.0027495278045535088\n",
      "16 -> ILSVRC2012_val_00041372 std: 0.0011466650757938623 std_pooled: 0.0031630084849894047\n",
      "17 -> ILSVRC2012_val_00023667 std: 0.0011285296641290188 std_pooled: 0.0031268023885786533\n",
      "18 -> ILSVRC2012_val_00034819 std: 0.0007128846482373774 std_pooled: 0.0019870162941515446\n",
      "19 -> ILSVRC2012_val_00018999 std: 0.0015319848898798227 std_pooled: 0.004262559115886688\n",
      "20 -> ILSVRC2012_val_00005503 std: 0.0014828027924522758 std_pooled: 0.004074105992913246\n",
      "21 -> ILSVRC2012_val_00037813 std: 0.0011647280771285295 std_pooled: 0.003278047079220414\n",
      "22 -> ILSVRC2012_val_00043355 std: 0.0015114923007786274 std_pooled: 0.0039026790764182806\n",
      "23 -> ILSVRC2012_val_00019214 std: 0.000772207451518625 std_pooled: 0.002151216147467494\n",
      "24 -> ILSVRC2012_val_00013726 std: 0.001420076354406774 std_pooled: 0.003955451305955648\n",
      "25 -> ILSVRC2012_val_00004647 std: 0.001334583037532866 std_pooled: 0.0036907577887177467\n",
      "26 -> ILSVRC2012_val_00032173 std: 0.0013149827718734741 std_pooled: 0.003657533088698983\n",
      "27 -> ILSVRC2012_val_00014807 std: 0.0009226780384778976 std_pooled: 0.0025808282662183046\n",
      "28 -> ILSVRC2012_val_00006355 std: 0.001138382707722485 std_pooled: 0.0031645852141082287\n",
      "29 -> ILSVRC2012_val_00024088 std: 0.000820811081212014 std_pooled: 0.002299676416441798\n",
      "30 -> ILSVRC2012_val_00011145 std: 0.0008022884139791131 std_pooled: 0.0022660200484097004\n",
      "31 -> ILSVRC2012_val_00023472 std: 0.001099628396332264 std_pooled: 0.0030181605834513903\n",
      "32 -> ILSVRC2012_val_00034374 std: 0.0018442831933498383 std_pooled: 0.005090435966849327\n",
      "33 -> ILSVRC2012_val_00019095 std: 0.0010756903793662786 std_pooled: 0.0030033958610147238\n",
      "34 -> ILSVRC2012_val_00019778 std: 0.001266228617168963 std_pooled: 0.0035390807315707207\n",
      "35 -> ILSVRC2012_val_00045955 std: 0.0017289355164393783 std_pooled: 0.004787679295986891\n",
      "36 -> ILSVRC2012_val_00047362 std: 0.0015326172579079866 std_pooled: 0.004253237042576075\n",
      "37 -> ILSVRC2012_val_00019831 std: 0.0006996916490606964 std_pooled: 0.0019363095052540302\n",
      "38 -> ILSVRC2012_val_00020249 std: 0.0006035970873199403 std_pooled: 0.0016799864824861288\n",
      "39 -> ILSVRC2012_val_00033614 std: 0.0011133227963000536 std_pooled: 0.0031009356025606394\n",
      "40 -> ILSVRC2012_val_00002061 std: 0.0010085494723170996 std_pooled: 0.0028703995048999786\n",
      "41 -> ILSVRC2012_val_00030999 std: 0.0014207044150680304 std_pooled: 0.003966789226979017\n",
      "42 -> ILSVRC2012_val_00014642 std: 0.0015458419220522046 std_pooled: 0.0043091727420687675\n",
      "43 -> ILSVRC2012_val_00017042 std: 0.0008895379723981023 std_pooled: 0.0024848058819770813\n",
      "44 -> ILSVRC2012_val_00020777 std: 0.001176630612462759 std_pooled: 0.0032649249769747257\n",
      "45 -> ILSVRC2012_val_00001990 std: 0.0014083520509302616 std_pooled: 0.0038722986355423927\n",
      "46 -> ILSVRC2012_val_00021425 std: 0.0016318882117047906 std_pooled: 0.004534479230642319\n",
      "47 -> ILSVRC2012_val_00017829 std: 0.0010239799739792943 std_pooled: 0.0028606040868908167\n",
      "48 -> ILSVRC2012_val_00023875 std: 0.0011848143767565489 std_pooled: 0.0032554955687373877\n",
      "49 -> ILSVRC2012_val_00000122 std: 0.0012534343404695392 std_pooled: 0.0034823280293494463\n",
      "50 -> ILSVRC2012_val_00018553 std: 0.0016264495206996799 std_pooled: 0.004522425122559071\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get all the castle images in the data folder\n",
    "castle_filenames = os.listdir('../data/castle')\n",
    "\n",
    "for i, fname in enumerate(castle_filenames, start=1):\n",
    "  # Image is in RGB mode with range [0,1]\n",
    "  img_path = f'../data/castle/{fname}'\n",
    "  # Extract image name without extension\n",
    "  img_name = os.path.basename(img_path).split('.')[0]\n",
    "\n",
    "  R = lrp_workflow(img_path)\n",
    "  torch.save(R, f'./artifacts/heuristic-standard-deviation/relevance_scores_{img_name}.pt')\n",
    "  pooled_relevance_scores = R[0].sum(dim=0)\n",
    "  torch.save(pooled_relevance_scores, f'./artifacts/heuristic-standard-deviation/pooled_relevance_scores_{img_name}.csv')\n",
    "\n",
    "  with open(f'./artifacts/heuristic-standard-deviation/std_relevance_scores_{img_name}.txt', \"w\") as f:\n",
    "    f.write(f'Standard deviation of relevance scores of {fname}: {torch.std(R)}')\n",
    "  \n",
    "  with open(f'./artifacts/heuristic-standard-deviation/std_pooled_relevance_scores_{img_name}.txt', \"w\") as f:\n",
    "    f.write(f'Standard deviation of pooled relevance scores of {fname}: {torch.std(R[0].sum(dim=0))}')\n",
    "\n",
    "  print(f'{i} -> {img_name} std: {torch.std(R)} std_pooled: {torch.std(R[0].sum(dim=0))}')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75ce43d651e7ed94697eb2e711875277eac8301956987ff4981f0cf80965cb87"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
